
const input = document.getElementById("input");
const chatHistory = document.getElementById("chatHistory");
const status = document.getElementById("status");
const toggleSound = document.getElementById("toggleSound");
let soundEnabled = true;

// === Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ===
function loadHistory() {
  const saved = sessionStorage.getItem("hub_history");
  if (!saved) return;
  const history = JSON.parse(saved);
  history.forEach(entry => appendMessage(entry.q, entry.a, false));
}
function saveMessage(q, a) {
  const existing = JSON.parse(sessionStorage.getItem("hub_history") || "[]");
  existing.unshift({ q, a });
  sessionStorage.setItem("hub_history", JSON.stringify(existing));
}
function appendMessage(q, a, save = true) {
  const wrapper = document.createElement("div");
  wrapper.className = "entry";

  const qDiv = document.createElement("div");
  qDiv.className = "question";
  qDiv.textContent = "Ð’Ð¾Ð¿Ñ€Ð¾Ñ: " + q;

  const aDiv = document.createElement("div");
  aDiv.className = "answer";
  aDiv.textContent = "ÐžÑ‚Ð²ÐµÑ‚: " + a;

  wrapper.appendChild(qDiv);
  wrapper.appendChild(aDiv);
  chatHistory.insertBefore(wrapper, chatHistory.firstChild);

  if (save) saveMessage(q, a);
  if (soundEnabled) speak(a);
}

// === ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ===
async function sendToHub(userText, audioBase64 = null) {
  status.textContent = "â³ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°...";
  const body = audioBase64
    ? { audio: audioBase64, shouldGreet: false }
    : { text: userText, shouldGreet: false };

  const res = await fetch("/.netlify/functions/ask", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(body)
  });

  const data = await res.json();
  const answer = data.text || "ÐÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.";
  const q = userText || data.transcript || "â€¦";
  appendMessage(q, answer);
  status.textContent = "Ð“Ð¾Ñ‚Ð¾Ð² ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñâ€¦";
  input.value = "";
}

// === ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° ===
function speak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  speechSynthesis.speak(utterance);
}
toggleSound.addEventListener("click", () => {
  soundEnabled = !soundEnabled;
  toggleSound.textContent = soundEnabled ? "ðŸ”Š ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°" : "ðŸ”‡ ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°";
  toggleSound.className = soundEnabled ? "sound-on" : "sound-off";
});

// === ÐšÐ½Ð¾Ð¿ÐºÐ¸ ===
document.getElementById("sendBtn").addEventListener("click", () => {
  const text = input.value.trim();
  if (text) sendToHub(text);
});
document.getElementById("speakBtn").addEventListener("click", async () => {
  if (!navigator.mediaDevices) return alert("ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ.");
  status.textContent = "ðŸŽ™ï¸ Ð¡Ð»ÑƒÑˆÐ°ÑŽ (5 ÑÐµÐºÑƒÐ½Ð´)...";

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const recorder = new MediaRecorder(stream);
  const chunks = [];
  recorder.ondataavailable = e => chunks.push(e.data);
  recorder.start();

  setTimeout(() => {
    recorder.stop();
    status.textContent = "â³ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ€ÐµÑ‡Ð¸...";
  }, 5000);

  recorder.onstop = async () => {
    const blob = new Blob(chunks, { type: "audio/webm" });
    const reader = new FileReader();
    reader.onloadend = async () => {
      const base64 = reader.result.split(",")[1];
      await sendToHub("", base64);
    };
    reader.readAsDataURL(blob);
  };
});

loadHistory();
