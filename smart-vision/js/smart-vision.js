document.addEventListener("DOMContentLoaded", () => {
  const micBtn = document.getElementById("micBtn");
  const status = document.getElementById("status");
  const waves = micBtn.querySelector(".waves");
  let isTalking = false;
  let audioContext, analyser, microphone, dataArray;
  let animationId;
  let lastStatus = "";

  micBtn.addEventListener("click", async () => {
    isTalking = !isTalking;

    if (isTalking) {
      micBtn.classList.add("active", "pulse");
      waves.classList.add("show");
      updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∞–ª—Å—è‚Ä¶");
      startMicVisualization();
    } else {
      micBtn.classList.remove("active", "pulse");
      waves.classList.remove("show");
      updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω.");
      stopMicVisualization();
    }
  });

  async function startMicVisualization() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      microphone = audioContext.createMediaStreamSource(stream);
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      microphone.connect(analyser);

      function animate() {
        analyser.getByteTimeDomainData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += Math.abs(dataArray[i] - 128);
        }
        const volume = sum / dataArray.length;

        const scale = 1 + volume / 60;
        const opacity = Math.min(0.8, volume / 80);

        waves.querySelectorAll("span").forEach((wave, i) => {
          wave.style.transform = `scale(${scale + i * 0.2})`;
          wave.style.opacity = opacity;
        });

        // üí¨ –†–µ–∞–∫—Ü–∏—è –Ω–∞ –≥—Ä–æ–º–∫–æ—Å—Ç—å
        let newStatus = "";
        if (volume < 2) {
          newStatus = "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω üéô";
        } else if (volume < 10) {
          newStatus = "–ì–æ–≤–æ—Ä–∏—Ç–µ —á—É—Ç—å –≥—Ä–æ–º—á–µ üó£Ô∏è";
        } else if (volume < 35) {
          newStatus = "–°–ª—ã—à—É –æ—Ç–ª–∏—á–Ω–æ üëÇ";
        } else {
          newStatus = "–û—á–µ–Ω—å –≥—Ä–æ–º–∫–æ! üîä";
        }

        if (newStatus !== lastStatus) {
          updateStatus(newStatus);
          lastStatus = newStatus;
        }

        animationId = requestAnimationFrame(animate);
      }

      animate();
    } catch (err) {
      console.error("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É:", err);
      updateStatus("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É üòï");
      isTalking = false;
    }
  }

  function stopMicVisualization() {
    if (animationId) cancelAnimationFrame(animationId);
    if (audioContext) audioContext.close();
    updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω.");
  }

  // ‚ú® –ü–ª–∞–≤–Ω–∞—è —Å–º–µ–Ω–∞ —Å—Ç–∞—Ç—É—Å–∞
  function updateStatus(text) {
    status.style.opacity = 0;
    setTimeout(() => {
      status.textContent = text;
      status.style.opacity = 1;
    }, 200);
  }
});
