document.addEventListener("DOMContentLoaded", () => {
  const micBtn = document.getElementById("micBtn");
  const status = document.getElementById("status");
  const waves = micBtn.querySelector(".waves");
  let isTalking = false;
  let audioContext, analyser, microphone, dataArray, stream;
  let animationId;
  let lastStatus = "";

  micBtn.addEventListener("click", async () => {
    isTalking = !isTalking;

    if (isTalking) {
      micBtn.classList.add("active", "pulse");
      waves.classList.add("show");
      updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∞–ª—Å—è‚Ä¶");
      startMicVisualization();
    } else {
      micBtn.classList.remove("active", "pulse");
      waves.classList.remove("show");
      updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω.");
      stopMicVisualization(true); // üëà –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    }
  });

  async function startMicVisualization() {
    try {
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      microphone = audioContext.createMediaStreamSource(stream);
      dataArray = new Uint8Array(analyser.frequencyBinCount);
      microphone.connect(analyser);

      function animate() {
        analyser.getByteTimeDomainData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += Math.abs(dataArray[i] - 128);
        }
        const volume = sum / dataArray.length;

        const scale = 1 + volume / 60;
        const opacity = Math.min(0.8, volume / 80);

        waves.querySelectorAll("span").forEach((wave, i) => {
          wave.style.transform = `scale(${scale + i * 0.2})`;
          wave.style.opacity = opacity;
        });

        let newStatus = "";
        if (volume < 2) {
          newStatus = "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω üéô";
        } else if (volume < 10) {
          newStatus = "–ì–æ–≤–æ—Ä–∏—Ç–µ —á—É—Ç—å –≥—Ä–æ–º—á–µ üó£Ô∏è";
        } else if (volume < 35) {
          newStatus = "–°–ª—ã—à—É –æ—Ç–ª–∏—á–Ω–æ üëÇ";
        } else {
          newStatus = "–û—á–µ–Ω—å –≥—Ä–æ–º–∫–æ! üîä";
        }

        if (newStatus !== lastStatus) {
          updateStatus(newStatus);
          lastStatus = newStatus;
        }

        animationId = requestAnimationFrame(animate);
      }

      animate();
    } catch (err) {
      console.error("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É:", err);
      updateStatus("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É üòï");
      isTalking = false;
    }
  }

  function stopMicVisualization(forceStop = false) {
    if (animationId) cancelAnimationFrame(animationId);
    if (audioContext) audioContext.close();

    // üîí –ü–æ–ª–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    if (forceStop && stream) {
      const tracks = stream.getTracks();
      tracks.forEach((track) => track.stop());
      stream = null;
      console.log("[Smart Vision] –ú–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á—ë–Ω ‚úÖ");
    }

    updateStatus("–†–∞–∑–≥–æ–≤–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω.");
  }

  function updateStatus(text) {
    status.style.opacity = 0;
    setTimeout(() => {
      status.textContent = text;
      status.style.opacity = 1;
    }, 200);
  }
});
